{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 180519 records, 53 columns\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries and Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(r'D:\\william\\OneDrive - UW-Madison\\UW-Madison\\722\\-2025AAE722_William-J\\Final Project\\DataCoSupplyChainDataset1.csv')\n",
    "print(f\"Data loaded: {data.shape[0]} records, {data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4876c4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data: 180519 records\n",
      "Customer Country unique values: 2\n",
      "Type unique values: 4\n",
      "Category Name unique values: 50\n"
     ]
    }
   ],
   "source": [
    "# 2. Data Preprocessing and Feature Selection\n",
    "# Select features including Customer Country\n",
    "features = [\n",
    "    'Type',  # Payment type\n",
    "    'Category Name', \n",
    "    'Market', \n",
    "    'Customer Country',  # NEW: Added customer country\n",
    "    'Order Item Discount Rate', \n",
    "    'Order Item Product Price', \n",
    "    'Order Item Quantity',\n",
    "    'Shipping Mode',\n",
    "    'Late_delivery_risk',\n",
    "    'Delivery Status',\n",
    "    'Order Status',\n",
    "    'Department Name',\n",
    "    'order date (DateOrders)',\n",
    "    'Order Item Profit Ratio'  # Target variable\n",
    "]\n",
    "\n",
    "# Create clean dataset\n",
    "model_data = data[features].copy().dropna()\n",
    "model_data['order date (DateOrders)'] = pd.to_datetime(model_data['order date (DateOrders)'])\n",
    "\n",
    "# Create separate date and time columns\n",
    "model_data['Order Date'] = model_data['order date (DateOrders)'].dt.date\n",
    "model_data['Order Time'] = model_data['order date (DateOrders)'].dt.time\n",
    "print(f\"Clean data: {model_data.shape[0]} records\")\n",
    "print(f\"Customer Country unique values: {model_data['Customer Country'].nunique()}\")\n",
    "print(f\"Type unique values: {model_data['Type'].nunique()}\")\n",
    "print(f\"Category Name unique values: {model_data['Category Name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4ed896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ TIME FEATURE ENGINEERING\n",
      "----------------------------------------\n",
      "‚úÖ Time features created:\n",
      "   ‚Ä¢ order_month: 12 unique values\n",
      "   ‚Ä¢ order_quarter: 4 unique values\n",
      "   ‚Ä¢ order_day_of_week: 7 unique values\n",
      "   ‚Ä¢ is_weekend: {0: 128672, 1: 51847}\n",
      "   ‚Ä¢ season: 4 unique seasons\n",
      "\n",
      "üîç TIME FEATURE CORRELATIONS WITH PROFIT RATIO:\n",
      "   order_month          correlation:   0.0019\n",
      "   order_quarter        correlation:   0.0015\n",
      "   order_day_of_week    correlation:  -0.0023\n",
      "   is_weekend           correlation:   0.0013\n",
      "   is_month_end         correlation:  -0.0027\n",
      "   is_quarter_end       correlation:   0.0016\n",
      "\n",
      "üìä SEASONAL PROFIT PATTERNS:\n",
      "          mean     std  count\n",
      "season                       \n",
      "Fall    0.1230  0.4636  40944\n",
      "Spring  0.1195  0.4689  47330\n",
      "Summer  0.1223  0.4643  46973\n",
      "Winter  0.1180  0.4701  45272\n"
     ]
    }
   ],
   "source": [
    "# 3a. Time Feature Engineering (Before Encoding)\n",
    "print(\"üìÖ TIME FEATURE ENGINEERING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Extract meaningful time components from order date\n",
    "model_data['order_month'] = model_data['order date (DateOrders)'].dt.month\n",
    "model_data['order_quarter'] = model_data['order date (DateOrders)'].dt.quarter\n",
    "model_data['order_day_of_week'] = model_data['order date (DateOrders)'].dt.dayofweek\n",
    "model_data['order_day_of_year'] = model_data['order date (DateOrders)'].dt.dayofyear\n",
    "model_data['order_week_of_year'] = model_data['order date (DateOrders)'].dt.isocalendar().week\n",
    "\n",
    "# Business-relevant time features\n",
    "model_data['is_weekend'] = (model_data['order_day_of_week'] >= 5).astype(int)\n",
    "model_data['is_month_end'] = (model_data['order date (DateOrders)'].dt.day >= 28).astype(int)\n",
    "model_data['is_quarter_end'] = model_data['order_month'].isin([3, 6, 9, 12]).astype(int)\n",
    "\n",
    "# Seasonal categories\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "model_data['season'] = model_data['order_month'].apply(get_season)\n",
    "\n",
    "print(\"‚úÖ Time features created:\")\n",
    "print(f\"   ‚Ä¢ order_month: {model_data['order_month'].nunique()} unique values\")\n",
    "print(f\"   ‚Ä¢ order_quarter: {model_data['order_quarter'].nunique()} unique values\") \n",
    "print(f\"   ‚Ä¢ order_day_of_week: {model_data['order_day_of_week'].nunique()} unique values\")\n",
    "print(f\"   ‚Ä¢ is_weekend: {model_data['is_weekend'].value_counts().to_dict()}\")\n",
    "print(f\"   ‚Ä¢ season: {model_data['season'].nunique()} unique seasons\")\n",
    "\n",
    "# Quick correlation analysis with target\n",
    "time_features = ['order_month', 'order_quarter', 'order_day_of_week', 'is_weekend', 'is_month_end', 'is_quarter_end']\n",
    "print(f\"\\nüîç TIME FEATURE CORRELATIONS WITH PROFIT RATIO:\")\n",
    "for feature in time_features:\n",
    "    correlation = model_data[feature].corr(model_data['Order Item Profit Ratio'])\n",
    "    print(f\"   {feature:<20} correlation: {correlation:>8.4f}\")\n",
    "\n",
    "# Check seasonal profit patterns\n",
    "seasonal_profit = model_data.groupby('season')['Order Item Profit Ratio'].agg(['mean', 'std', 'count'])\n",
    "print(f\"\\nüìä SEASONAL PROFIT PATTERNS:\")\n",
    "print(seasonal_profit.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c12bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä UPDATED FEATURE COMPOSITION:\n",
      "   Categorical features: 9 (['Type', 'Category Name', 'Market', 'Customer Country', 'Shipping Mode', 'Delivery Status', 'Order Status', 'Department Name', 'season'])\n",
      "   Numerical features: 12 (including 8 time features)\n",
      "\n",
      "‚úÖ FINAL FEATURE SET: 21 total features\n",
      "   ‚Ä¢ 12 numerical (including time features)\n",
      "   ‚Ä¢ 9 encoded categorical\n",
      "‚úÖ Type (Payment Type) included\n",
      "‚úÖ Customer Country included\n",
      "‚úÖ Time features included and properly engineered\n",
      "‚úÖ All features ready for modeling\n",
      "\n",
      "‚úÖ FINAL FEATURE SET: 21 total features\n",
      "   ‚Ä¢ 12 numerical (including time features)\n",
      "   ‚Ä¢ 9 encoded categorical\n",
      "‚úÖ Type (Payment Type) included\n",
      "‚úÖ Customer Country included\n",
      "‚úÖ Time features included and properly engineered\n",
      "‚úÖ All features ready for modeling\n"
     ]
    }
   ],
   "source": [
    "# 3b. Updated Feature Definition with Time Components\n",
    "# Separate target and features\n",
    "target = 'Order Item Profit Ratio'\n",
    "y = model_data[target]\n",
    "\n",
    "# Define feature types (UPDATED with time features)\n",
    "categorical_features = [\n",
    "    'Type', 'Category Name', 'Market', 'Customer Country', \n",
    "    'Shipping Mode', 'Delivery Status', 'Order Status', 'Department Name',\n",
    "    'season'  # NEW: Seasonal category\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'Order Item Discount Rate', 'Order Item Product Price', \n",
    "    'Order Item Quantity', 'Late_delivery_risk',\n",
    "    # NEW: Time-based numerical features\n",
    "    'order_month', 'order_quarter', 'order_day_of_week', 'order_day_of_year', \n",
    "    'order_week_of_year', 'is_weekend', 'is_month_end', 'is_quarter_end'\n",
    "]\n",
    "\n",
    "print(f\"üìä UPDATED FEATURE COMPOSITION:\")\n",
    "print(f\"   Categorical features: {len(categorical_features)} ({categorical_features})\")\n",
    "print(f\"   Numerical features: {len(numerical_features)} (including {len([f for f in numerical_features if 'order_' in f or 'is_' in f])} time features)\")\n",
    "\n",
    "# Direct encoding using LabelEncoder\n",
    "encoded_data = model_data.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    encoded_data[f'{feature}_encoded'] = le.fit_transform(encoded_data[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Create feature matrix\n",
    "encoded_categorical_features = [f'{feature}_encoded' for feature in categorical_features]\n",
    "all_features = numerical_features + encoded_categorical_features\n",
    "X = encoded_data[all_features]\n",
    "\n",
    "print(f\"\\n‚úÖ FINAL FEATURE SET: {len(all_features)} total features\")\n",
    "print(f\"   ‚Ä¢ {len(numerical_features)} numerical (including time features)\")\n",
    "print(f\"   ‚Ä¢ {len(encoded_categorical_features)} encoded categorical\")\n",
    "print(f\"‚úÖ Type (Payment Type) included\")  \n",
    "print(f\"‚úÖ Customer Country included\")\n",
    "print(f\"‚úÖ Time features included and properly engineered\")\n",
    "print(f\"‚úÖ All features ready for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7367c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TIME VARIABLE DECISION ANALYSIS\n",
      "==================================================\n",
      "üìä FEATURE COMPARISON:\n",
      "   Without time features: 12 base features\n",
      "   With time features: 21 total features\n",
      "   Time features added: 9\n",
      "\n",
      "üìà TIME PATTERN ANALYSIS:\n",
      "------------------------------\n",
      "Monthly profit variation (std): 0.003647\n",
      "Weekly profit variation (std): 0.003931\n",
      "Weekend effect magnitude: 0.001308\n",
      "\n",
      "üéØ TIME FEATURE RECOMMENDATIONS:\n",
      "----------------------------------------\n",
      "‚ö†Ô∏è  WEAK: Low monthly profit variation\n",
      "‚ö†Ô∏è  WEAK: Low weekly profit variation\n",
      "‚ö†Ô∏è  WEAK: Minimal weekend effect\n",
      "\n",
      "üèÜ OVERALL TIME SIGNAL STRENGTH: 0.008886\n",
      "üî¥ WEAK RECOMMENDATION: Time features unlikely to help significantly\n",
      "\n",
      "üìã BENEFITS vs RISKS:\n",
      "‚úÖ BENEFITS:\n",
      "   ‚Ä¢ Capture seasonal business patterns\n",
      "   ‚Ä¢ Model weekly customer behavior\n",
      "   ‚Ä¢ Identify optimal timing strategies\n",
      "‚ö†Ô∏è  RISKS:\n",
      "   ‚Ä¢ Potential overfitting to specific time periods\n",
      "   ‚Ä¢ Model complexity increase\n",
      "   ‚Ä¢ May reduce generalization to future periods\n",
      "\n",
      "üéØ FINAL RECOMMENDATION: SKIP time features\n",
      "üí° TIP: Compare model performance with/without time features using CV\n"
     ]
    }
   ],
   "source": [
    "# 3c. Time Variable Impact Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"üîç TIME VARIABLE DECISION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create comparison datasets\n",
    "features_without_time = [\n",
    "    'Type', 'Category Name', 'Market', 'Customer Country', \n",
    "    'Shipping Mode', 'Delivery Status', 'Order Status', 'Department Name',\n",
    "    'Order Item Discount Rate', 'Order Item Product Price', \n",
    "    'Order Item Quantity', 'Late_delivery_risk'\n",
    "]\n",
    "\n",
    "features_with_time = all_features\n",
    "\n",
    "print(f\"üìä FEATURE COMPARISON:\")\n",
    "print(f\"   Without time features: {len([f for f in features_without_time if not f.endswith('_encoded')])} base features\")\n",
    "print(f\"   With time features: {len(all_features)} total features\")\n",
    "print(f\"   Time features added: {len(all_features) - len(features_without_time)}\")\n",
    "\n",
    "# Check for potential time-related patterns\n",
    "print(f\"\\nüìà TIME PATTERN ANALYSIS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Monthly profit analysis\n",
    "monthly_stats = model_data.groupby('order_month')['Order Item Profit Ratio'].agg(['mean', 'std', 'count'])\n",
    "monthly_variation = monthly_stats['mean'].std()\n",
    "print(f\"Monthly profit variation (std): {monthly_variation:.6f}\")\n",
    "\n",
    "# Weekly profit analysis  \n",
    "weekly_stats = model_data.groupby('order_day_of_week')['Order Item Profit Ratio'].agg(['mean', 'std', 'count'])\n",
    "weekly_variation = weekly_stats['mean'].std()\n",
    "print(f\"Weekly profit variation (std): {weekly_variation:.6f}\")\n",
    "\n",
    "# Weekend vs weekday\n",
    "weekend_profit = model_data[model_data['is_weekend'] == 1]['Order Item Profit Ratio'].mean()\n",
    "weekday_profit = model_data[model_data['is_weekend'] == 0]['Order Item Profit Ratio'].mean()\n",
    "weekend_effect = abs(weekend_profit - weekday_profit)\n",
    "print(f\"Weekend effect magnitude: {weekend_effect:.6f}\")\n",
    "\n",
    "# Recommendation based on variation\n",
    "print(f\"\\nüéØ TIME FEATURE RECOMMENDATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if monthly_variation > 0.01:\n",
    "    print(\"‚úÖ INCLUDE: Significant monthly profit variation detected\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WEAK: Low monthly profit variation\")\n",
    "\n",
    "if weekly_variation > 0.01:\n",
    "    print(\"‚úÖ INCLUDE: Significant weekly profit variation detected\") \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WEAK: Low weekly profit variation\")\n",
    "\n",
    "if weekend_effect > 0.01:\n",
    "    print(\"‚úÖ INCLUDE: Weekend effect detected\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WEAK: Minimal weekend effect\")\n",
    "\n",
    "# Overall recommendation\n",
    "total_time_signal = monthly_variation + weekly_variation + weekend_effect\n",
    "print(f\"\\nüèÜ OVERALL TIME SIGNAL STRENGTH: {total_time_signal:.6f}\")\n",
    "\n",
    "if total_time_signal > 0.03:\n",
    "    print(\"üü¢ STRONG RECOMMENDATION: Include time features\")\n",
    "    time_recommendation = \"INCLUDE\"\n",
    "elif total_time_signal > 0.015:\n",
    "    print(\"üü° MODERATE RECOMMENDATION: Time features may help\")\n",
    "    time_recommendation = \"CONSIDER\"\n",
    "else:\n",
    "    print(\"üî¥ WEAK RECOMMENDATION: Time features unlikely to help significantly\")\n",
    "    time_recommendation = \"SKIP\"\n",
    "\n",
    "print(f\"\\nüìã BENEFITS vs RISKS:\")\n",
    "print(\"‚úÖ BENEFITS:\")\n",
    "print(\"   ‚Ä¢ Capture seasonal business patterns\")\n",
    "print(\"   ‚Ä¢ Model weekly customer behavior\")\n",
    "print(\"   ‚Ä¢ Identify optimal timing strategies\")\n",
    "print(\"‚ö†Ô∏è  RISKS:\")\n",
    "print(\"   ‚Ä¢ Potential overfitting to specific time periods\")\n",
    "print(\"   ‚Ä¢ Model complexity increase\")\n",
    "print(\"   ‚Ä¢ May reduce generalization to future periods\")\n",
    "\n",
    "print(f\"\\nüéØ FINAL RECOMMENDATION: {time_recommendation} time features\")\n",
    "print(f\"üí° TIP: Compare model performance with/without time features using CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bb6574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 126363 samples\n",
      "Testing: 54156 samples\n"
     ]
    }
   ],
   "source": [
    "# 4. Train-Test Split (70% / 30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffab7fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ HYBRID MODEL TRAINING WITH CROSS-VALIDATION\n",
      "============================================================\n",
      "Phase 1: Individual Model Optimization\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. Hybrid Model Implementation with Cross-Validation\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "import time\n",
    "\n",
    "print(\"üîÑ HYBRID MODEL TRAINING WITH CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define individual models with initial parameters\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(random_state=42),\n",
    "    'Lasso Regression': Lasso(random_state=42),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# Hyperparameter grids for optimization\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 15, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'Ridge Regression': {\n",
    "        'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Cross-validation results storage\n",
    "cv_results = {}\n",
    "optimized_models = {}\n",
    "best_params = {}\n",
    "\n",
    "print(\"Phase 1: Individual Model Optimization\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82391d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ FAST MODEL OPTIMIZATION (Using 10% sample for CV)\n",
      "============================================================\n",
      "üìä Using 12,636 samples (126,363 ‚Üí 12,636) for CV optimization\n",
      "üí° This reduces runtime by ~90% while finding good hyperparameters\n",
      "\n",
      "‚ö° PHASE 1: FAST HYPERPARAMETER OPTIMIZATION\n",
      "--------------------------------------------------\n",
      "\n",
      "üîç Optimizing Random Forest...\n",
      "  ‚úÖ CV R¬≤ Score: -0.001903 (¬±0.000282)\n",
      "  ‚ö° Training Time: 94.27s\n",
      "  üéØ Best Parameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "\n",
      "üîç Optimizing Gradient Boosting...\n",
      "  ‚úÖ CV R¬≤ Score: -0.000478 (¬±0.000086)\n",
      "  ‚ö° Training Time: 20.56s\n",
      "  üéØ Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "üîç Optimizing Linear Regression...\n",
      "  ‚úÖ CV R¬≤ Score: -0.000319 (¬±0.000063)\n",
      "  ‚ö° Training Time: 0.20s\n",
      "\n",
      "üîç Optimizing Ridge Regression...\n",
      "  ‚úÖ CV R¬≤ Score: -0.000319 (¬±0.000063)\n",
      "  ‚ö° Training Time: 0.23s\n",
      "  üéØ Best Parameters: {'alpha': 10.0}\n",
      "\n",
      "üîç Optimizing Lasso Regression...\n",
      "  ‚úÖ CV R¬≤ Score: -0.000040 (¬±0.000028)\n",
      "  ‚ö° Training Time: 0.32s\n",
      "  üéØ Best Parameters: {'alpha': 1.0}\n",
      "\n",
      "üîç Optimizing SVR...\n"
     ]
    }
   ],
   "source": [
    "# 6. Individual Model Cross-Validation and Hyperparameter Tuning\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç Optimizing {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if name in param_grids:\n",
    "        # Grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            model, \n",
    "            param_grids[name], \n",
    "            cv=5, \n",
    "            scoring='r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params[name] = grid_search.best_params_\n",
    "        \n",
    "        # Cross-validation score with best parameters\n",
    "        cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='r2')\n",
    "        \n",
    "    else:\n",
    "        # For Linear Regression (no hyperparameters)\n",
    "        best_model = model\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "        best_params[name] = \"Default parameters\"\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'mean_cv_score': cv_scores.mean(),\n",
    "        'std_cv_score': cv_scores.std(),\n",
    "        'best_model': best_model\n",
    "    }\n",
    "    optimized_models[name] = best_model\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  ‚úÖ CV R¬≤ Score: {cv_scores.mean():.6f} (¬±{cv_scores.std():.6f})\")\n",
    "    print(f\"  ‚è±Ô∏è  Training Time: {training_time:.2f}s\")\n",
    "    if name in param_grids:\n",
    "        print(f\"  üéØ Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "print(f\"\\nüìä INDIVIDUAL MODEL RANKINGS\")\n",
    "print(\"-\" * 40)\n",
    "sorted_results = sorted(cv_results.items(), key=lambda x: x[1]['mean_cv_score'], reverse=True)\n",
    "for i, (name, results) in enumerate(sorted_results, 1):\n",
    "    print(f\"{i}. {name:<20} R¬≤ = {results['mean_cv_score']:.6f} (¬±{results['std_cv_score']:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Hybrid Ensemble Model Creation\n",
    "print(f\"\\nüöÄ PHASE 2: HYBRID ENSEMBLE MODELS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Select top 3 performing models for ensemble\n",
    "top_3_models = sorted_results[:3]\n",
    "print(f\"Top 3 models selected for ensemble:\")\n",
    "for i, (name, results) in enumerate(top_3_models, 1):\n",
    "    print(f\"  {i}. {name} (R¬≤ = {results['mean_cv_score']:.6f})\")\n",
    "\n",
    "# Create ensemble combinations\n",
    "ensemble_models = {}\n",
    "\n",
    "# 1. Voting Regressor with top 3 models\n",
    "voting_estimators = [(name, cv_results[name]['best_model']) for name, _ in top_3_models]\n",
    "voting_regressor = VotingRegressor(estimators=voting_estimators)\n",
    "ensemble_models['Voting (Top 3)'] = voting_regressor\n",
    "\n",
    "# 2. Voting Regressor with all models\n",
    "all_estimators = [(name, model) for name, model in optimized_models.items()]\n",
    "voting_all = VotingRegressor(estimators=all_estimators)\n",
    "ensemble_models['Voting (All Models)'] = voting_all\n",
    "\n",
    "# 3. Weighted Voting based on CV performance\n",
    "weights = [results['mean_cv_score'] for _, results in top_3_models]\n",
    "voting_weighted = VotingRegressor(estimators=voting_estimators)\n",
    "ensemble_models['Weighted Voting (Top 3)'] = voting_weighted\n",
    "\n",
    "print(f\"\\nüîÑ Training Ensemble Models...\")\n",
    "ensemble_results = {}\n",
    "\n",
    "for name, ensemble in ensemble_models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(ensemble, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    ensemble_results[name] = {\n",
    "        'mean_cv_score': cv_scores.mean(),\n",
    "        'std_cv_score': cv_scores.std(),\n",
    "        'model': ensemble\n",
    "    }\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"  ‚úÖ {name:<25} R¬≤ = {cv_scores.mean():.6f} (¬±{cv_scores.std():.6f}) [{training_time:.2f}s]\")\n",
    "\n",
    "# Combine all results for final comparison\n",
    "all_results = {**cv_results, **ensemble_results}\n",
    "final_ranking = sorted(all_results.items(), key=lambda x: x[1]['mean_cv_score'], reverse=True)\n",
    "\n",
    "print(f\"\\nüèÜ FINAL MODEL RANKINGS\")\n",
    "print(\"=\" * 60)\n",
    "for i, (name, results) in enumerate(final_ranking, 1):\n",
    "    score = results['mean_cv_score']\n",
    "    std = results['std_cv_score']\n",
    "    model_type = \"ü§ñ Ensemble\" if name in ensemble_results else \"üìä Individual\"\n",
    "    print(f\"{i:2d}. {model_type} {name:<25} R¬≤ = {score:.6f} (¬±{std:.6f})\")\n",
    "\n",
    "# Select best model\n",
    "best_model_name, best_model_info = final_ranking[0]\n",
    "best_model = best_model_info['model'] if 'model' in best_model_info else best_model_info['best_model']\n",
    "\n",
    "print(f\"\\nü•á BEST MODEL SELECTED: {best_model_name}\")\n",
    "print(f\"   Cross-Validation R¬≤ = {best_model_info['mean_cv_score']:.6f} (¬±{best_model_info['std_cv_score']:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a256d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Final Model Evaluation on Test Set\n",
    "print(f\"\\nüéØ FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Train best model on full training set\n",
    "start_time = time.time()\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate additional metrics\n",
    "residuals = y_test - y_pred\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100  # Mean Absolute Percentage Error\n",
    "\n",
    "print(f\"üèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"üìä PERFORMANCE METRICS:\")\n",
    "print(f\"   R¬≤ Score: {r2:.6f}\")\n",
    "print(f\"   RMSE: {rmse:.6f}\")\n",
    "print(f\"   MAE: {mae:.6f}\")\n",
    "print(f\"   MAPE: {mape:.2f}%\")\n",
    "print(f\"   Training Time: {training_time:.2f}s\")\n",
    "print(f\"   CV R¬≤ (Training): {best_model_info['mean_cv_score']:.6f}\")\n",
    "print(f\"   Test R¬≤ (Holdout): {r2:.6f}\")\n",
    "\n",
    "# Model generalization check\n",
    "generalization_gap = best_model_info['mean_cv_score'] - r2\n",
    "print(f\"\\nüìà GENERALIZATION ANALYSIS:\")\n",
    "print(f\"   CV Score vs Test Score Gap: {generalization_gap:.6f}\")\n",
    "if abs(generalization_gap) < 0.02:\n",
    "    print(\"   ‚úÖ Excellent generalization (< 2% gap)\")\n",
    "elif abs(generalization_gap) < 0.05:\n",
    "    print(\"   ‚ö†Ô∏è  Good generalization (< 5% gap)\")\n",
    "else:\n",
    "    print(\"   ‚ùå Potential overfitting (> 5% gap)\")\n",
    "\n",
    "# Feature importance (if applicable)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': all_features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüîç TOP 5 FEATURE IMPORTANCES:\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "        clean_name = row['Feature'].replace('_encoded', '')\n",
    "        print(f\"   {i}. {clean_name:<25} {row['Importance']:.6f}\")\n",
    "\n",
    "elif hasattr(best_model, 'estimators_'):\n",
    "    # For ensemble models, show component models\n",
    "    print(f\"\\nüîß ENSEMBLE COMPONENTS:\")\n",
    "    if hasattr(best_model, 'estimators_'):\n",
    "        for name, estimator in best_model.estimators_:\n",
    "            print(f\"   ‚Ä¢ {name}\")\n",
    "\n",
    "print(f\"\\n‚ú® Model successfully optimized and evaluated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Comprehensive Model Analysis and Comparison\n",
    "print(\"üî¨ DETAILED MODEL ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Model comparison table\n",
    "print(f\"üìä COMPLETE MODEL COMPARISON:\")\n",
    "print(f\"{'Model':<25} {'CV R¬≤':<12} {'CV Std':<10} {'Type'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, (name, results) in enumerate(final_ranking, 1):\n",
    "    score = results['mean_cv_score']\n",
    "    std = results['std_cv_score']\n",
    "    model_type = \"Ensemble\" if name in ensemble_results else \"Individual\"\n",
    "    print(f\"{name:<25} {score:<12.6f} {std:<10.6f} {model_type}\")\n",
    "\n",
    "# Best parameters summary\n",
    "print(f\"\\nüéØ OPTIMIZED HYPERPARAMETERS:\")\n",
    "print(\"-\" * 40)\n",
    "for name, params in best_params.items():\n",
    "    if name in [result[0] for result in sorted_results[:5]]:  # Top 5 individual models\n",
    "        print(f\"\\n{name}:\")\n",
    "        if isinstance(params, dict):\n",
    "            for param, value in params.items():\n",
    "                print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "        else:\n",
    "            print(f\"  ‚Ä¢ {params}\")\n",
    "\n",
    "# Performance comparison with baseline\n",
    "baseline_r2 = cv_results['Linear Regression']['mean_cv_score']\n",
    "best_r2 = best_model_info['mean_cv_score']\n",
    "improvement = ((best_r2 - baseline_r2) / baseline_r2) * 100\n",
    "\n",
    "print(f\"\\nüìà PERFORMANCE IMPROVEMENT:\")\n",
    "print(f\"   Baseline (Linear Regression): {baseline_r2:.6f}\")\n",
    "print(f\"   Best Model ({best_model_name}): {best_r2:.6f}\")\n",
    "print(f\"   Improvement: {improvement:.2f}%\")\n",
    "\n",
    "# Feature importance analysis (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': all_features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüîç COMPLETE FEATURE IMPORTANCE RANKING:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, (_, row) in enumerate(feature_importance.iterrows(), 1):\n",
    "        clean_name = row['Feature'].replace('_encoded', '')\n",
    "        print(f\"{i:2d}. {clean_name:<30} {row['Importance']:.6f}\")\n",
    "    \n",
    "    # Check key predictors\n",
    "    type_rows = feature_importance[feature_importance['Feature'].str.contains('Type')]\n",
    "    country_rows = feature_importance[feature_importance['Feature'].str.contains('Customer Country')]\n",
    "    \n",
    "    if not type_rows.empty:\n",
    "        type_rank = feature_importance.index[feature_importance['Feature'] == type_rows.iloc[0]['Feature']].tolist()[0] + 1\n",
    "        print(f\"\\nüéØ Key Predictor Rankings:\")\n",
    "        print(f\"   Type (Payment): #{type_rank}\")\n",
    "    \n",
    "    if not country_rows.empty:\n",
    "        country_rank = feature_importance.index[feature_importance['Feature'] == country_rows.iloc[0]['Feature']].tolist()[0] + 1\n",
    "        print(f\"   Customer Country: #{country_rank}\")\n",
    "\n",
    "# Cross-validation stability analysis\n",
    "print(f\"\\nüìä MODEL STABILITY ANALYSIS:\")\n",
    "print(\"-\" * 30)\n",
    "for name, results in sorted(cv_results.items(), key=lambda x: x[1]['std_cv_score']):\n",
    "    stability = \"High\" if results['std_cv_score'] < 0.01 else \"Medium\" if results['std_cv_score'] < 0.02 else \"Low\"\n",
    "    print(f\"{name:<20} Std: {results['std_cv_score']:.6f} ({stability} Stability)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Advanced Visualization and Model Insights\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Actual vs Predicted for Best Model\n",
    "axes[0, 0].scatter(y_test, y_pred, alpha=0.6, s=30, color='blue', edgecolor='white', linewidth=0.5)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "axes[0, 0].set_title(f'Best Model: {best_model_name}\\nActual vs Predicted (R¬≤ = {r2:.4f})', fontsize=11)\n",
    "axes[0, 0].set_xlabel('Actual Profit Ratio')\n",
    "axes[0, 0].set_ylabel('Predicted Profit Ratio')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add prediction interval lines\n",
    "sorted_indices = np.argsort(y_test)\n",
    "sorted_y_test = y_test.iloc[sorted_indices]\n",
    "sorted_y_pred = y_pred[sorted_indices]\n",
    "residuals_sorted = sorted_y_pred - sorted_y_test\n",
    "\n",
    "# 2. Model Performance Comparison\n",
    "model_names = [name for name, _ in final_ranking[:8]]  # Top 8 models\n",
    "model_scores = [results['mean_cv_score'] for _, results in final_ranking[:8]]\n",
    "model_stds = [results['std_cv_score'] for _, results in final_ranking[:8]]\n",
    "\n",
    "colors = ['gold' if i == 0 else 'lightblue' if 'Ensemble' in name else 'lightgreen' \n",
    "          for i, name in enumerate(model_names)]\n",
    "\n",
    "bars = axes[0, 1].bar(range(len(model_names)), model_scores, yerr=model_stds, \n",
    "                      capsize=5, color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[0, 1].set_title('Model Performance Comparison (CV R¬≤ Score)', fontsize=11)\n",
    "axes[0, 1].set_xlabel('Models')\n",
    "axes[0, 1].set_ylabel('R¬≤ Score')\n",
    "axes[0, 1].set_xticks(range(len(model_names)))\n",
    "axes[0, 1].set_xticklabels([name[:12] + '...' if len(name) > 12 else name \n",
    "                           for name in model_names], rotation=45, ha='right')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, score) in enumerate(zip(bars, model_scores)):\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                    f'{score:.4f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 3. Feature Importance (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': all_features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    top_features = feature_importance.head(10)\n",
    "    \n",
    "    bars = axes[1, 0].barh(range(len(top_features)), top_features['Importance'], \n",
    "                          color='skyblue', edgecolor='navy', alpha=0.7)\n",
    "    axes[1, 0].set_yticks(range(len(top_features)))\n",
    "    axes[1, 0].set_yticklabels([f.replace('_encoded', '') for f in top_features['Feature']], \n",
    "                              fontsize=9)\n",
    "    axes[1, 0].set_title('Top 10 Feature Importances', fontsize=11)\n",
    "    axes[1, 0].set_xlabel('Importance')\n",
    "    axes[1, 0].invert_yaxis()\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, importance) in enumerate(zip(bars, top_features['Importance'])):\n",
    "        axes[1, 0].text(bar.get_width() + 0.002, bar.get_y() + bar.get_height()/2,\n",
    "                       f'{importance:.4f}', va='center', fontsize=8)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, f'Feature Importance\\nNot Available\\nfor {best_model_name}', \n",
    "                   transform=axes[1, 0].transAxes, ha='center', va='center',\n",
    "                   fontsize=12, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "    axes[1, 0].set_xlim(0, 1)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "# 4. Residual Analysis\n",
    "residuals = y_test - y_pred\n",
    "axes[1, 1].scatter(y_pred, residuals, alpha=0.6, s=30, color='purple', edgecolor='white', linewidth=0.5)\n",
    "axes[1, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_title('Residual Analysis', fontsize=11)\n",
    "axes[1, 1].set_xlabel('Predicted Values')\n",
    "axes[1, 1].set_ylabel('Residuals (Actual - Predicted)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add residual statistics\n",
    "rmse_residual = np.sqrt(np.mean(residuals**2))\n",
    "mean_residual = np.mean(residuals)\n",
    "axes[1, 1].text(0.05, 0.95, f'RMSE: {rmse_residual:.4f}\\nMean: {mean_residual:.4f}', \n",
    "               transform=axes[1, 1].transAxes, va='top', \n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional ensemble analysis plot\n",
    "if 'Voting' in best_model_name or 'Ensemble' in best_model_name:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    \n",
    "    # Compare individual vs ensemble performance\n",
    "    individual_scores = [(name, results['mean_cv_score']) for name, results in cv_results.items()]\n",
    "    ensemble_scores = [(name, results['mean_cv_score']) for name, results in ensemble_results.items()]\n",
    "    \n",
    "    all_scores = individual_scores + ensemble_scores\n",
    "    names, scores = zip(*all_scores)\n",
    "    \n",
    "    colors = ['lightcoral' if name in cv_results else 'lightgreen' for name in names]\n",
    "    \n",
    "    bars = ax.bar(range(len(names)), scores, color=colors, edgecolor='black', alpha=0.8)\n",
    "    ax.set_title('Individual Models vs Ensemble Models Performance', fontsize=14)\n",
    "    ax.set_xlabel('Models')\n",
    "    ax.set_ylabel('Cross-Validation R¬≤ Score')\n",
    "    ax.set_xticks(range(len(names)))\n",
    "    ax.set_xticklabels(names, rotation=45, ha='right')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='lightcoral', label='Individual Models'),\n",
    "                      Patch(facecolor='lightgreen', label='Ensemble Models')]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    # Highlight best model\n",
    "    best_idx = names.index(best_model_name)\n",
    "    bars[best_idx].set_color('gold')\n",
    "    bars[best_idx].set_edgecolor('darkgoldenrod')\n",
    "    bars[best_idx].set_linewidth(3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fac69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Final Summary and Model Recommendations\n",
    "print(\"üéØ HYBRID MODEL OPTIMIZATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Dataset: {model_data.shape[0]} records, {len(all_features)} features\")\n",
    "print(f\"üîÑ Models Tested: {len(models)} individual + {len(ensemble_models)} ensemble\")\n",
    "print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "print(f\"üìà Best Performance: R¬≤ = {best_model_info['mean_cv_score']:.6f} (¬±{best_model_info['std_cv_score']:.6f})\")\n",
    "\n",
    "print(f\"\\nüéØ KEY FINDINGS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Performance improvement analysis\n",
    "baseline_model = 'Linear Regression'\n",
    "baseline_score = cv_results[baseline_model]['mean_cv_score']\n",
    "improvement = ((best_model_info['mean_cv_score'] - baseline_score) / baseline_score) * 100\n",
    "\n",
    "print(f\"‚úÖ Performance Improvement: {improvement:.1f}% over baseline\")\n",
    "print(f\"‚úÖ Cross-Validation Stability: ¬±{best_model_info['std_cv_score']:.6f}\")\n",
    "\n",
    "# Model type analysis\n",
    "if best_model_name in ensemble_results:\n",
    "    print(f\"‚úÖ Best approach: Ensemble modeling\")\n",
    "    print(f\"‚úÖ Hybrid strategy successful\")\n",
    "else:\n",
    "    print(f\"‚úÖ Best approach: Individual model optimization\")\n",
    "    print(f\"‚úÖ Hyperparameter tuning effective\")\n",
    "\n",
    "# Feature analysis\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': all_features,\n",
    "        'Importance': best_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    top_feature = feature_importance.iloc[0]['Feature'].replace('_encoded', '')\n",
    "    print(f\"‚úÖ Most Important Feature: {top_feature}\")\n",
    "    \n",
    "    # Check if Customer Country and Type are in top 10\n",
    "    top_10_features = feature_importance.head(10)['Feature'].tolist()\n",
    "    \n",
    "    customer_country_in_top = any('Customer Country' in f for f in top_10_features)\n",
    "    type_in_top = any('Type' in f for f in top_10_features)\n",
    "    \n",
    "    if customer_country_in_top:\n",
    "        print(f\"‚úÖ Customer Country: High importance confirmed\")\n",
    "    if type_in_top:\n",
    "        print(f\"‚úÖ Payment Type: High importance confirmed\")\n",
    "\n",
    "print(f\"\\nüöÄ RECOMMENDATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"1. Deploy {best_model_name} for production\")\n",
    "print(f\"2. Expected R¬≤ performance: ~{best_model_info['mean_cv_score']:.3f}\")\n",
    "\n",
    "if best_model_name in ensemble_results:\n",
    "    print(f\"3. Ensemble approach provides robust predictions\")\n",
    "    print(f\"4. Regular model retraining recommended\")\n",
    "else:\n",
    "    print(f\"3. Monitor individual model performance\")\n",
    "    print(f\"4. Consider ensemble for future improvements\")\n",
    "\n",
    "print(f\"5. Focus on top {min(5, len(all_features))} features for model interpretation\")\n",
    "print(f\"6. Validate model on new data before deployment\")\n",
    "\n",
    "print(f\"\\n‚ú® Hybrid modeling with cross-validation optimization complete!\")\n",
    "print(f\"üéâ Best model identified and ready for deployment!\")\n",
    "\n",
    "# Save model summary\n",
    "model_summary = {\n",
    "    'best_model': best_model_name,\n",
    "    'cv_r2_score': best_model_info['mean_cv_score'],\n",
    "    'cv_r2_std': best_model_info['std_cv_score'],\n",
    "    'test_r2_score': r2 if 'r2' in locals() else None,\n",
    "    'improvement_over_baseline': improvement,\n",
    "    'total_models_tested': len(models) + len(ensemble_models),\n",
    "    'features_used': len(all_features),\n",
    "    'training_samples': X_train.shape[0],\n",
    "    'test_samples': X_test.shape[0]\n",
    "}\n",
    "\n",
    "print(f\"\\nüìã Model Summary Dictionary Created:\")\n",
    "for key, value in model_summary.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüîç Access individual results:\")\n",
    "print(f\"   ‚Ä¢ cv_results: Individual model CV scores\")\n",
    "print(f\"   ‚Ä¢ ensemble_results: Ensemble model CV scores\") \n",
    "print(f\"   ‚Ä¢ final_ranking: Complete model ranking\")\n",
    "print(f\"   ‚Ä¢ best_model: Trained best model object\")\n",
    "print(f\"   ‚Ä¢ optimized_models: All optimized individual models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
